{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Models\n",
    "\n",
    "Logistic Regression, Random Forest, XGBoost, other tree based models, Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages and set formatting options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>NAME_EDUCATION_TYPE</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>OCCUPATION_TYPE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BIRTH</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>YEARS_EMPLOYED</th>\n",
       "      <th>YEARS_LAST_PHONE_CHANGE</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.481121</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0</td>\n",
       "      <td>Higher education</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Core staff</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>45.931507</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>3.254795</td>\n",
       "      <td>2.268493</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.566907</td>\n",
       "      <td>0.770087</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>38.591781</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>8.295890</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.721940</td>\n",
       "      <td>0.642656</td>\n",
       "      <td>0.481121</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>39.953425</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.556164</td>\n",
       "      <td>0.515068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112500.0</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.706428</td>\n",
       "      <td>0.556727</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Laborers</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>48.542466</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>21.380822</td>\n",
       "      <td>0.654795</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.786179</td>\n",
       "      <td>0.565608</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>1</td>\n",
       "      <td>Secondary / secondary special</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>Drivers</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>30.920548</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>2.043836</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  APARTMENTS_MODE  BASEMENTAREA_AVG  ENTRANCES_AVG  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  FLOORSMAX_MODE  LANDAREA_AVG  LIVE_CITY_NOT_WORK_CITY            NAME_EDUCATION_TYPE  NONLIVINGAREA_MODE OCCUPATION_TYPE  REGION_POPULATION_RELATIVE  REGION_RATING_CLIENT  REG_CITY_NOT_LIVE_CITY  TOTALAREA_MODE  YEARS_BEGINEXPLUATATION_MODE  YEARS_BIRTH  YEARS_BUILD_MODE  YEARS_EMPLOYED  YEARS_LAST_PHONE_CHANGE  TARGET\n",
       "0          270000.0           0.0924            0.0529         0.0345      0.311267      0.622246      0.481121          0.2917        0.0130                        0               Higher education              0.0000      Core staff                    0.003541                     1                       0          0.0714                        0.9851    45.931507            0.8040        3.254795                 2.268493       0\n",
       "1          225000.0           0.1502            0.0973         0.1379      0.478860      0.566907      0.770087          0.3333        0.0931                        0  Secondary / secondary special              0.0000         Drivers                    0.016612                     2                       0          0.1417                        0.9806    38.591781            0.7452        8.295890                 0.010959       0\n",
       "2          189000.0           0.3561            0.1335         0.1724      0.721940      0.642656      0.481121          0.6667        0.1758                        0  Secondary / secondary special              0.1060        Laborers                    0.010006                     2                       0          0.3811                        0.9985    39.953425            0.9804        0.556164                 0.515068       0\n",
       "3          112500.0           0.0284            0.0617         0.1034      0.478860      0.706428      0.556727          0.0833        0.0279                        0  Secondary / secondary special              0.0000        Laborers                    0.046220                     1                       0          0.0238                        0.9881    48.542466            0.8432       21.380822                 0.654795       0\n",
       "4          135000.0           0.1460            0.1455         0.3103      0.478860      0.786179      0.565608          0.1667        0.0861                        1  Secondary / secondary special              0.0045         Drivers                    0.026392                     2                       0          0.0967                        0.9861    30.920548            0.8171        2.043836                 0.010959       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('feature_selected_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80603, 23)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variable Encoding\n",
    "After examining the cleaned and reduced training set, there are still two categorical variables that will need to be encoded before applying any machine learning models. Let's examine those first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Secondary / secondary special    54306\n",
       "Higher education                 22086\n",
       "Incomplete higher                 3530\n",
       "Lower secondary                    633\n",
       "Academic degree                     48\n",
       "Name: NAME_EDUCATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NAME_EDUCATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are only 5 categories present for education type, we can use One Hot Encoding with k-1 dummies created out of k categories. Before we proceed, let's examine the other categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Laborers                 18363\n",
       "Others                   13289\n",
       "Sales staff              10219\n",
       "Core staff                8379\n",
       "Managers                  6415\n",
       "Drivers                   5964\n",
       "High skill tech staff     3966\n",
       "Accountants               3263\n",
       "Medicine staff            2463\n",
       "Security staff            1981\n",
       "Cooking staff             1718\n",
       "Cleaning staff            1456\n",
       "Private service staff      917\n",
       "Low-skill Laborers         644\n",
       "Secretaries                471\n",
       "Waiters/barmen staff       406\n",
       "Realty agents              280\n",
       "HR staff                   209\n",
       "IT staff                   200\n",
       "Name: OCCUPATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OCCUPATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no clear ordinal positioning between different occupations, we can use One Hot Encoding for occupation type as well. We will use the pandas function get_dummies() to encode both categorical variables at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns = ['NAME_EDUCATION_TYPE', 'OCCUPATION_TYPE'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>APARTMENTS_MODE</th>\n",
       "      <th>BASEMENTAREA_AVG</th>\n",
       "      <th>ENTRANCES_AVG</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "      <th>FLOORSMAX_MODE</th>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <th>LIVE_CITY_NOT_WORK_CITY</th>\n",
       "      <th>NONLIVINGAREA_MODE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>REGION_RATING_CLIENT</th>\n",
       "      <th>REG_CITY_NOT_LIVE_CITY</th>\n",
       "      <th>TOTALAREA_MODE</th>\n",
       "      <th>YEARS_BEGINEXPLUATATION_MODE</th>\n",
       "      <th>YEARS_BIRTH</th>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <th>YEARS_EMPLOYED</th>\n",
       "      <th>YEARS_LAST_PHONE_CHANGE</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Higher education</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Incomplete higher</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Lower secondary</th>\n",
       "      <th>NAME_EDUCATION_TYPE_Secondary / secondary special</th>\n",
       "      <th>OCCUPATION_TYPE_Cleaning staff</th>\n",
       "      <th>OCCUPATION_TYPE_Cooking staff</th>\n",
       "      <th>OCCUPATION_TYPE_Core staff</th>\n",
       "      <th>OCCUPATION_TYPE_Drivers</th>\n",
       "      <th>OCCUPATION_TYPE_HR staff</th>\n",
       "      <th>OCCUPATION_TYPE_High skill tech staff</th>\n",
       "      <th>OCCUPATION_TYPE_IT staff</th>\n",
       "      <th>OCCUPATION_TYPE_Laborers</th>\n",
       "      <th>OCCUPATION_TYPE_Low-skill Laborers</th>\n",
       "      <th>OCCUPATION_TYPE_Managers</th>\n",
       "      <th>OCCUPATION_TYPE_Medicine staff</th>\n",
       "      <th>OCCUPATION_TYPE_Others</th>\n",
       "      <th>OCCUPATION_TYPE_Private service staff</th>\n",
       "      <th>OCCUPATION_TYPE_Realty agents</th>\n",
       "      <th>OCCUPATION_TYPE_Sales staff</th>\n",
       "      <th>OCCUPATION_TYPE_Secretaries</th>\n",
       "      <th>OCCUPATION_TYPE_Security staff</th>\n",
       "      <th>OCCUPATION_TYPE_Waiters/barmen staff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>270000.0</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.311267</td>\n",
       "      <td>0.622246</td>\n",
       "      <td>0.481121</td>\n",
       "      <td>0.2917</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.003541</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0714</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>45.931507</td>\n",
       "      <td>0.8040</td>\n",
       "      <td>3.254795</td>\n",
       "      <td>2.268493</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.1502</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.566907</td>\n",
       "      <td>0.770087</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.9806</td>\n",
       "      <td>38.591781</td>\n",
       "      <td>0.7452</td>\n",
       "      <td>8.295890</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>189000.0</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>0.1724</td>\n",
       "      <td>0.721940</td>\n",
       "      <td>0.642656</td>\n",
       "      <td>0.481121</td>\n",
       "      <td>0.6667</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>39.953425</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.556164</td>\n",
       "      <td>0.515068</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112500.0</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.706428</td>\n",
       "      <td>0.556727</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.046220</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0238</td>\n",
       "      <td>0.9881</td>\n",
       "      <td>48.542466</td>\n",
       "      <td>0.8432</td>\n",
       "      <td>21.380822</td>\n",
       "      <td>0.654795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.1460</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.3103</td>\n",
       "      <td>0.478860</td>\n",
       "      <td>0.786179</td>\n",
       "      <td>0.565608</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.0861</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0967</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>30.920548</td>\n",
       "      <td>0.8171</td>\n",
       "      <td>2.043836</td>\n",
       "      <td>0.010959</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AMT_INCOME_TOTAL  APARTMENTS_MODE  BASEMENTAREA_AVG  ENTRANCES_AVG  EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  FLOORSMAX_MODE  LANDAREA_AVG  LIVE_CITY_NOT_WORK_CITY  NONLIVINGAREA_MODE  REGION_POPULATION_RELATIVE  REGION_RATING_CLIENT  REG_CITY_NOT_LIVE_CITY  TOTALAREA_MODE  YEARS_BEGINEXPLUATATION_MODE  YEARS_BIRTH  YEARS_BUILD_MODE  YEARS_EMPLOYED  YEARS_LAST_PHONE_CHANGE  TARGET  NAME_EDUCATION_TYPE_Higher education  NAME_EDUCATION_TYPE_Incomplete higher  NAME_EDUCATION_TYPE_Lower secondary  NAME_EDUCATION_TYPE_Secondary / secondary special  OCCUPATION_TYPE_Cleaning staff  OCCUPATION_TYPE_Cooking staff  OCCUPATION_TYPE_Core staff  OCCUPATION_TYPE_Drivers  OCCUPATION_TYPE_HR staff  OCCUPATION_TYPE_High skill tech staff  OCCUPATION_TYPE_IT staff  OCCUPATION_TYPE_Laborers  OCCUPATION_TYPE_Low-skill Laborers  OCCUPATION_TYPE_Managers  OCCUPATION_TYPE_Medicine staff  OCCUPATION_TYPE_Others  OCCUPATION_TYPE_Private service staff  OCCUPATION_TYPE_Realty agents  \\\n",
       "0          270000.0           0.0924            0.0529         0.0345      0.311267      0.622246      0.481121          0.2917        0.0130                        0              0.0000                    0.003541                     1                       0          0.0714                        0.9851    45.931507            0.8040        3.254795                 2.268493       0                                     1                                      0                                    0                                                  0                               0                              0                           1                        0                         0                                      0                         0                         0                                   0                         0                               0                       0                                      0                              0   \n",
       "1          225000.0           0.1502            0.0973         0.1379      0.478860      0.566907      0.770087          0.3333        0.0931                        0              0.0000                    0.016612                     2                       0          0.1417                        0.9806    38.591781            0.7452        8.295890                 0.010959       0                                     0                                      0                                    0                                                  1                               0                              0                           0                        1                         0                                      0                         0                         0                                   0                         0                               0                       0                                      0                              0   \n",
       "2          189000.0           0.3561            0.1335         0.1724      0.721940      0.642656      0.481121          0.6667        0.1758                        0              0.1060                    0.010006                     2                       0          0.3811                        0.9985    39.953425            0.9804        0.556164                 0.515068       0                                     0                                      0                                    0                                                  1                               0                              0                           0                        0                         0                                      0                         0                         1                                   0                         0                               0                       0                                      0                              0   \n",
       "3          112500.0           0.0284            0.0617         0.1034      0.478860      0.706428      0.556727          0.0833        0.0279                        0              0.0000                    0.046220                     1                       0          0.0238                        0.9881    48.542466            0.8432       21.380822                 0.654795       0                                     0                                      0                                    0                                                  1                               0                              0                           0                        0                         0                                      0                         0                         1                                   0                         0                               0                       0                                      0                              0   \n",
       "4          135000.0           0.1460            0.1455         0.3103      0.478860      0.786179      0.565608          0.1667        0.0861                        1              0.0045                    0.026392                     2                       0          0.0967                        0.9861    30.920548            0.8171        2.043836                 0.010959       0                                     0                                      0                                    0                                                  1                               0                              0                           0                        1                         0                                      0                         0                         0                                   0                         0                               0                       0                                      0                              0   \n",
       "\n",
       "   OCCUPATION_TYPE_Sales staff  OCCUPATION_TYPE_Secretaries  OCCUPATION_TYPE_Security staff  OCCUPATION_TYPE_Waiters/barmen staff  \n",
       "0                            0                            0                               0                                     0  \n",
       "1                            0                            0                               0                                     0  \n",
       "2                            0                            0                               0                                     0  \n",
       "3                            0                            0                               0                                     0  \n",
       "4                            0                            0                               0                                     0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80603, 43)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both features OCCUPATION_TYPE and NAME_EDUCATION_TYPE have been encoded. The dataset is ready for modeling. The dataset has "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with splitting the dataframe into independent and dependent variables. The independent variable (y) will be the target variable and the dependent variables (X) will consist of all the remaining predictor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[df.columns[~df.columns.isin(['TARGET'])]].copy()\n",
    "y = df['TARGET'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will split the data into a training and testing set, using a 70/30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline Logistic regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      1.00      0.87     18459\n",
      "          1       0.00      0.00      0.00      5722\n",
      "\n",
      "avg / total       0.58      0.76      0.66     24181\n",
      "\n",
      "Accuracy score: 0.7633679335015094\n",
      "\n",
      "Confusion matrix: \n",
      " [[18459     0]\n",
      " [ 5722     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score\n",
    "\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('\\nClassification report: \\n',classification_report(y_test, y_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('\\nConfusion matrix: \\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline logistic regression model was unsuccessful in predicting any defaulters in the test dataset. The accuracy score of 0.76 only reflects the values where Target = 0. Let's see if we can produce better results with parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.001: 0.7614242587155204,\n",
       " 0.1: 0.7614242587155204,\n",
       " 1: 0.7614242587155204,\n",
       " 10: 0.7614242587155204,\n",
       " 100: 0.7614242587155204}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Try log reg with different values for c\n",
    "\n",
    "def reg_param_c(X,y, c_values, test_size):\n",
    "    c_scores = {}\n",
    "    for i in c_values:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size, random_state = 42)\n",
    "        logreg = LogisticRegression(C = i)\n",
    "        logreg.fit(X_train, y_train)\n",
    "        c_scores[i] = accuracy_score(y_test, logreg.predict(X_test))\n",
    "    return c_scores\n",
    "\n",
    "reg_param_c(X,y, [0.001, 0.1, 1, 10, 100], 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75829097, 0.24170903],\n",
       "       [0.88885379, 0.11114621],\n",
       "       [0.76052382, 0.23947618],\n",
       "       [0.77447801, 0.22552199],\n",
       "       [0.64698282, 0.35301718],\n",
       "       [0.66081333, 0.33918667],\n",
       "       [0.88404333, 0.11595667],\n",
       "       [0.78106972, 0.21893028],\n",
       "       [0.74111827, 0.25888173],\n",
       "       [0.78289787, 0.21710213],\n",
       "       [0.68956865, 0.31043135],\n",
       "       [0.78145327, 0.21854673],\n",
       "       [0.79095803, 0.20904197],\n",
       "       [0.80610219, 0.19389781],\n",
       "       [0.73928875, 0.26071125],\n",
       "       [0.6736156 , 0.3263844 ],\n",
       "       [0.72177991, 0.27822009],\n",
       "       [0.87226785, 0.12773215],\n",
       "       [0.67326536, 0.32673464],\n",
       "       [0.7468995 , 0.2531005 ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.predict_proba(X_test)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite tuning parameters, the probability of predicting a default (Target = 1) is relatively low and we would have to change our threshold significantly from the default of 0.5 to get any predictions for the majority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "We will use random forest, which combines many decision trees to try to accomplish better overall model performance. Let's start with the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import RandomForestClassifier and set random_state for duplicating results\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(random_state = 42)\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance for out of the box model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature AMT_INCOME_TOTAL Importance 0.15120192088977052\n",
      "Feature APARTMENTS_MODE Importance 0.12180508241693673\n",
      "Feature BASEMENTAREA_AVG Importance 0.10645504508112003\n",
      "Feature ENTRANCES_AVG Importance 0.09382327229936242\n",
      "Feature EXT_SOURCE_1 Importance 0.0828751650045905\n",
      "Feature EXT_SOURCE_2 Importance 0.06328979783547661\n",
      "Feature EXT_SOURCE_3 Importance 0.04544765949827793\n",
      "Feature FLOORSMAX_MODE Importance 0.04206080753518144\n",
      "Feature LANDAREA_AVG Importance 0.036736346091766355\n",
      "Feature LIVE_CITY_NOT_WORK_CITY Importance 0.03547126002978609\n",
      "Feature NONLIVINGAREA_MODE Importance 0.031779991385613174\n",
      "Feature REGION_POPULATION_RELATIVE Importance 0.027379857891961096\n",
      "Feature REGION_RATING_CLIENT Importance 0.026457962924412437\n",
      "Feature REG_CITY_NOT_LIVE_CITY Importance 0.024752886172016392\n",
      "Feature TOTALAREA_MODE Importance 0.024437177301917176\n",
      "Feature YEARS_BEGINEXPLUATATION_MODE Importance 0.020446017048314048\n",
      "Feature YEARS_BIRTH Importance 0.018849219796352838\n",
      "Feature YEARS_BUILD_MODE Importance 0.0058485199138721385\n",
      "Feature YEARS_EMPLOYED Importance 0.0038801866050391285\n",
      "Feature YEARS_LAST_PHONE_CHANGE Importance 0.0036600617045737483\n",
      "Feature NAME_EDUCATION_TYPE_Higher education Importance 0.003175112454019014\n",
      "Feature NAME_EDUCATION_TYPE_Incomplete higher Importance 0.003105017559065164\n",
      "Feature NAME_EDUCATION_TYPE_Lower secondary Importance 0.0030539151813119675\n",
      "Feature NAME_EDUCATION_TYPE_Secondary / secondary special Importance 0.0029016892646810434\n",
      "Feature OCCUPATION_TYPE_Cleaning staff Importance 0.0028203225995558803\n",
      "Feature OCCUPATION_TYPE_Cooking staff Importance 0.002452607467861504\n",
      "Feature OCCUPATION_TYPE_Core staff Importance 0.001967234890580938\n",
      "Feature OCCUPATION_TYPE_Drivers Importance 0.001729554094432055\n",
      "Feature OCCUPATION_TYPE_HR staff Importance 0.001644701934137761\n",
      "Feature OCCUPATION_TYPE_High skill tech staff Importance 0.0014767396550771222\n",
      "Feature OCCUPATION_TYPE_IT staff Importance 0.0013368095337984458\n",
      "Feature OCCUPATION_TYPE_Laborers Importance 0.0012397919323041636\n",
      "Feature OCCUPATION_TYPE_Low-skill Laborers Importance 0.0012279539017451854\n",
      "Feature OCCUPATION_TYPE_Managers Importance 0.0011162430445269403\n",
      "Feature OCCUPATION_TYPE_Medicine staff Importance 0.0009546010100813255\n",
      "Feature OCCUPATION_TYPE_Others Importance 0.0008296228544299981\n",
      "Feature OCCUPATION_TYPE_Private service staff Importance 0.0008239054468385237\n",
      "Feature OCCUPATION_TYPE_Realty agents Importance 0.0004948242748762158\n",
      "Feature OCCUPATION_TYPE_Sales staff Importance 0.0004787094566964721\n",
      "Feature OCCUPATION_TYPE_Secretaries Importance 0.00021538141892104646\n",
      "Feature OCCUPATION_TYPE_Security staff Importance 0.0002122004794274051\n",
      "Feature OCCUPATION_TYPE_Waiters/barmen staff Importance 8.482411929094125e-05\n"
     ]
    }
   ],
   "source": [
    "for feature, importance in zip(X_train.columns, pd.Series(classifier.feature_importances_).sort_values(ascending = False)):\n",
    "    print('Feature',feature, 'Importance', importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95     18459\n",
      "          1       0.96      0.67      0.79      5722\n",
      "\n",
      "avg / total       0.92      0.92      0.91     24181\n",
      "\n",
      "Accuracy score: 0.9159670815929862\n",
      "\n",
      "Confusion matrix: \n",
      " [[18317   142]\n",
      " [ 1890  3832]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification report: \\n',classification_report(y_test, y_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('\\nConfusion matrix: \\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline random forest model performed much better than logistic regression, with an accuracy of over 91%. However, since this is a binary imbalanced class problem, accuracy is not the best measure for evaluating performance. We will also calculate the Area under the Curve (AUC) and plot the Receiving Operating Characteristic (ROC) curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8310015930522615"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The baseline Random Forest Classifier model yielded an Area Under Curve of 0.831"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    20207\n",
      "1     3974\n",
      "dtype: int64\n",
      "0    18459\n",
      "1     5722\n",
      "Name: TARGET, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.Series(y_pred).value_counts())\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Same as running roc_auc_score(y_test, y_pred) above\n",
    "\n",
    "prob_def = classifier.predict_proba(X_test)[:,1]\n",
    "fp_rate, tp_rate, thresholds = roc_curve(y_test, prob_def)\n",
    "roc_auc = auc(fp_rate, tp_rate)\n",
    "plt.plot(fp_rate, tp_rate)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate (1-Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "Baseline predictive power is decent but let us see if we can do better with hyperparameter tuning. Let's start by finding the optimal number of estimators. We will try to compare performance tradeoff versus incremental improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score for 10 estimators is: 0.8310015930522615\n",
      "AUC score for 20 estimators is: 0.8321270077583356\n",
      "AUC score for 30 estimators is: 0.8377316996722608\n",
      "AUC score for 40 estimators is: 0.8359805417407774\n",
      "AUC score for 50 estimators is: 0.8347301062034209\n",
      "AUC score for 60 estimators is: 0.8353295387215124\n",
      "AUC score for 70 estimators is: 0.8376346795307563\n",
      "AUC score for 80 estimators is: 0.8372912722545837\n",
      "AUC score for 90 estimators is: 0.8373934996249565\n",
      "AUC score for 100 estimators is: 0.8371523197191566\n",
      "AUC score for 110 estimators is: 0.8379116709696367\n",
      "AUC score for 120 estimators is: 0.8379571206099676\n",
      "AUC score for 130 estimators is: 0.837917791830479\n",
      "AUC score for 140 estimators is: 0.838131884678475\n",
      "AUC score for 150 estimators is: 0.8385626739889014\n"
     ]
    }
   ],
   "source": [
    "#Find optimal estimators n\n",
    "\n",
    "for i in range(10,160,10):\n",
    "    class2 = RandomForestClassifier(n_estimators = i, n_jobs = -1, random_state = 42)\n",
    "    class2.fit(X_train, y_train)\n",
    "    y_pred = class2.predict(X_test)\n",
    "    print('AUC score for', i, 'estimators is:', roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance did not significantly improve as the number of estimators increased past a certain point. We will choose 70 estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10,\n",
       " 'n_jobs': 1,\n",
       " 'oob_score': False,\n",
       " 'random_state': 42,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will adjust the following hyperparameters:\n",
    "- bootstrap: method for sampling data points (with or without replacement)\n",
    "- max_depth: max levels in each decision tree\n",
    "- max_features: max features considered for splitting a node\n",
    "- min_samples_leaf: min number of data points allowed in a leaf node\n",
    "- min_samples_split: min number of data points put in a node before node is split\n",
    "- n_estimators: number of trees in the forest\n",
    "\n",
    "Since it will be too computationally expensive to exhaustively try every single parameter combination, we will use RandomizedSearchCV to take a random subset of possible parameter combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "bootstrap = [True, False]\n",
    "max_depth = [i for i in range(10,100,10)]\n",
    "max_depth.append(None)\n",
    "max_features = ['sqrt', 'log2']\n",
    "min_samples_leaf = [1, 2, 3, 4, 5]\n",
    "min_samples_split = [i for i in range(2,12,2)]\n",
    "n_estimators = [i for i in range(10,110,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': [True, False],\n",
       " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, None],\n",
       " 'max_features': ['sqrt', 'log2'],\n",
       " 'min_samples_leaf': [1, 2, 3, 4, 5],\n",
       " 'min_samples_split': [2, 4, 6, 8, 10],\n",
       " 'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_grid = {'bootstrap': bootstrap,\n",
    "                'max_depth': max_depth,\n",
    "                'max_features': max_features,\n",
    "                'min_samples_leaf': min_samples_leaf,\n",
    "                'min_samples_split': min_samples_split,\n",
    "                'n_estimators': n_estimators}\n",
    "random_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  5.4min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:  9.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'bootstrap': [True, False], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, None], 'max_features': ['sqrt', 'log2'], 'min_samples_leaf': [1, 2, 3, 4, 5], 'min_samples_split': [2, 4, 6, 8, 10], 'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv = RandomizedSearchCV(estimator = RandomForestClassifier(), param_distributions = random_grid, n_iter = 10, cv = 5, verbose = 2, random_state = 42, n_jobs = -1)\n",
    "rf_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'n_estimators': 90, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False}\n",
      "Best Estimator: RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
      "            max_depth=20, max_features='sqrt', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=2, min_samples_split=6,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Best Score: 0.9195349331820921\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', rf_cv.best_params_)\n",
    "print('Best Estimator:', rf_cv.best_estimator_)\n",
    "print('Best Score:', rf_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.91468, std: 0.00158, params: {'n_estimators': 10, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 50, 'bootstrap': False},\n",
       " mean: 0.91454, std: 0.00251, params: {'n_estimators': 10, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 20, 'bootstrap': True},\n",
       " mean: 0.90908, std: 0.00122, params: {'n_estimators': 10, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': False},\n",
       " mean: 0.91310, std: 0.00265, params: {'n_estimators': 20, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': False},\n",
       " mean: 0.91952, std: 0.00154, params: {'n_estimators': 50, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False},\n",
       " mean: 0.91879, std: 0.00216, params: {'n_estimators': 60, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 30, 'bootstrap': False},\n",
       " mean: 0.91078, std: 0.00176, params: {'n_estimators': 70, 'min_samples_split': 4, 'min_samples_leaf': 5, 'max_features': 'log2', 'max_depth': 10, 'bootstrap': True},\n",
       " mean: 0.91562, std: 0.00236, params: {'n_estimators': 70, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 90, 'bootstrap': True},\n",
       " mean: 0.91953, std: 0.00232, params: {'n_estimators': 90, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': False},\n",
       " mean: 0.91821, std: 0.00183, params: {'n_estimators': 30, 'min_samples_split': 6, 'min_samples_leaf': 2, 'max_features': 'log2', 'max_depth': 70, 'bootstrap': False}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cv.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pred = rf_cv.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for best estimator: 0.8389034776506399\n"
     ]
    }
   ],
   "source": [
    "print('AUC for best estimator:',roc_auc_score(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After hyperparameter tuning, we have an AUC score of 0.8389, which is an improvement over the baseline score of 0.8310."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "Extreme Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "#data_dm = xgb.DMatrix(data = X_train, label = y_train)\n",
    "\n",
    "xg_class = xgb.XGBClassifier(random_state = 42)\n",
    "xg_class.fit(X_train, y_train)\n",
    "y_pred = xg_class.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.99      0.95     18459\n",
      "          1       0.95      0.71      0.81      5722\n",
      "\n",
      "avg / total       0.92      0.92      0.92     24181\n",
      "\n",
      "Accuracy score: 0.9220048798643563\n",
      "\n",
      "Confusion matrix: \n",
      " [[18249   210]\n",
      " [ 1676  4046]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification report: \\n',classification_report(y_test, y_pred))\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('\\nConfusion matrix: \\n',confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8478594284519085"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this boosting technique out of the box yielded an AUC score of 0.8479."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 18 candidates, totalling 54 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:   45.3s\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  54 out of  54 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [1, 3, 5], 'min_child_weight': [1, 3], 'n_estimators': [20], 'learning_rate': [0.05, 0.1, 0.16]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [1, 3, 5],\n",
    "              \"min_child_weight\" : [1,3],\n",
    "              \"n_estimators\": [20],\n",
    "              \"learning_rate\": [0.05, 0.1,0.16]}\n",
    "grid_search = GridSearchCV(estimator = xgb.XGBClassifier(), param_grid = param_grid, cv = 3, verbose = 10, n_jobs = -1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.16, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 20}\n",
      "Best Estimator: XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "       colsample_bytree=1, gamma=0, learning_rate=0.16, max_delta_step=0,\n",
      "       max_depth=5, min_child_weight=3, missing=None, n_estimators=20,\n",
      "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
      "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "       silent=True, subsample=1)\n",
      "Best Score: 0.9202084293360746\n"
     ]
    }
   ],
   "source": [
    "print('Best Parameters:', grid_search.best_params_)\n",
    "print('Best Estimator:', grid_search.best_estimator_)\n",
    "print('Best Score:', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.76057, std: 0.00001, params: {'learning_rate': 0.05, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.76057, std: 0.00001, params: {'learning_rate': 0.05, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.90117, std: 0.00258, params: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.90117, std: 0.00258, params: {'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.90757, std: 0.00217, params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.90748, std: 0.00194, params: {'learning_rate': 0.05, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.90840, std: 0.00124, params: {'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.90840, std: 0.00124, params: {'learning_rate': 0.1, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.91656, std: 0.00184, params: {'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.91656, std: 0.00184, params: {'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.91634, std: 0.00096, params: {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.91762, std: 0.00093, params: {'learning_rate': 0.1, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.90840, std: 0.00124, params: {'learning_rate': 0.16, 'max_depth': 1, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.90840, std: 0.00124, params: {'learning_rate': 0.16, 'max_depth': 1, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.92016, std: 0.00124, params: {'learning_rate': 0.16, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.92016, std: 0.00124, params: {'learning_rate': 0.16, 'max_depth': 3, 'min_child_weight': 3, 'n_estimators': 20},\n",
       " mean: 0.91994, std: 0.00111, params: {'learning_rate': 0.16, 'max_depth': 5, 'min_child_weight': 1, 'n_estimators': 20},\n",
       " mean: 0.92021, std: 0.00139, params: {'learning_rate': 0.16, 'max_depth': 5, 'min_child_weight': 3, 'n_estimators': 20}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "best_pred_xgb = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95     18459\n",
      "          1       0.97      0.69      0.81      5722\n",
      "\n",
      "avg / total       0.93      0.92      0.92     24181\n",
      "\n",
      "Accuracy score: 0.9221702989950787\n",
      "\n",
      "Confusion matrix: \n",
      " [[18326   133]\n",
      " [ 1749  3973]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nClassification report: \\n',classification_report(y_test, best_pred_xgb))\n",
    "print('Accuracy score:',accuracy_score(y_test, best_pred_xgb))\n",
    "print('\\nConfusion matrix: \\n',confusion_matrix(y_test, best_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC for best estimator: 0.8435662434022754\n"
     ]
    }
   ],
   "source": [
    "print('AUC for best estimator:',roc_auc_score(y_test, best_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9193168189901162"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada = AdaBoostClassifier(random_state = 42)\n",
    "ada.fit(X_train, y_train)\n",
    "ada.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8483296838233118\n"
     ]
    }
   ],
   "source": [
    "print('AUC:',roc_auc_score(y_test, ada.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9244448120425127"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use cross val score - might be able to change parameter to precision or recall\n",
    "\n",
    "lgb = lgb.LGBMClassifier(random_state = 42)\n",
    "lgb.fit(X_train, y_train)\n",
    "lgb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.8491560899800816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saumit\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "print('AUC:',roc_auc_score(y_test, lgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_threshold(threshold):\n",
    "    print('Sensitivity:', tpr[thresholds > threshold][-1])\n",
    "    print('Specificity:', 1- fpr[thresholds > threshold][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.1, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern = BernoulliNB(binarize = 0.1)\n",
    "bern.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.8477730449526488\n",
      "AUC: 0.7420182270430936\n"
     ]
    }
   ],
   "source": [
    "y_pred = bern.predict(X_test)\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('AUC:',roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi = MultinomialNB()\n",
    "multi.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7390926760679872\n",
      "AUC: 0.608247253579681\n"
     ]
    }
   ],
   "source": [
    "y_pred = multi.predict(X_test)\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('AUC:',roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss = GaussianNB()\n",
    "gauss.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.7634919978495514\n",
      "AUC: 0.5002621461027613\n"
     ]
    }
   ],
   "source": [
    "y_pred = gauss.predict(X_test)\n",
    "print('Accuracy score:',accuracy_score(y_test, y_pred))\n",
    "print('AUC:',roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
